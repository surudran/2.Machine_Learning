{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ae7e523-b1ad-4e1c-9334-d3e9c03b538a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import pickle function to save / load the model.\n",
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "012f266b-5f07-474f-baf3-481c9970b10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"50_Startups.csv\")#read_csv function called to read the csv file and store to dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3136832c-1af6-4943-bf61-bbd6b2e38f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert categarical data to numerical data using the function get_dummies, drop_first will delete the first column\n",
    "dataset = pd.get_dummies(dataset, drop_first = True) \n",
    "independent = dataset[['R&D Spend', 'Administration', 'Marketing Spend', 'State_Florida', 'State_New York']]\n",
    "dependent = dataset[['Profit']]\n",
    "#The sklearn. model_selection module in Scikit-Learn provides functions for splitting data into training and test sets, evaluating machine learning models, and performing cross-validation.\n",
    "from sklearn.model_selection import train_test_split # import specific function train_test_spilit the function from sklearn.model_selection.  Split arrays or matrices into random train and test subsets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(independent, dependent, test_size = 0.30, random_state = 0) # split the dataset to train set for 70% and test set for 30% assigned to variables X_train, X_test, y_train, y_test respectively, # need to divide into X_train, X_test, y_train, y_test to use the sklearn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9cead111-5249-4ad2-acf8-97850b73fd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardisation\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train) #Calculate mean and deviation\n",
    "X_test = sc.transform(X_test) #transform will use the calculated mean and deviation values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad7746dc-baa0-4e32-90a2-f8b592f10227",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sutharsanurudrasingam/anaconda3/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "preinput = sc.transform([[1300,12000,4000,0,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da8faaf9-b5d4-4bf9-a652-cfcbe64ec444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.46755405, -4.33835385, -1.50744257, -0.5       ,  1.30088727]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preinput #display the pre-processed values for [1300,12000,4000,0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "515738fe-b42a-4379-847d-18cb50f11633",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sutharsanurudrasingam/anaconda3/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but SVR was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Load (read) the model from saved filename \"finalized_Mul_linear.sav\" and assinged to variable loaded_model\n",
    "loaded_model = pickle.load(open(\"finalized_model_SVM_linear.sav\", 'rb'))\n",
    "result = loaded_model.predict(preinput) #Find the predicted value for given input values and assigned to variable result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "692b2fac-c5e2-47a1-9232-2d5939ebfbfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([39001.78749507])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result #displays the values from variable result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42d06a6-5bfc-4a53-9292-c50b66973c57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6234f87-5757-40c1-b6c0-08f175d853b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
